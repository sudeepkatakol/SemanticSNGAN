{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import multiprocessing\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "CATEGORY_DICT = OrderedDict({\n",
    "0 : \"airplane\", \n",
    "1: \"automobile\",\n",
    "2: \"bird\",\n",
    "3:\"cat\",\n",
    "4:\"deer\",\n",
    "5:\"dog\",\n",
    "6:\"frog\",\n",
    "7:\"horse\",\n",
    "8:\"ship\",\n",
    "9:\"truck\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_data(X, BATCH_SIZE):\n",
    "    index = 0\n",
    "    while True:\n",
    "        if index + BATCH_SIZE <= len(X):\n",
    "            data = X[index:index+BATCH_SIZE]\n",
    "            index += BATCH_SIZE\n",
    "        else:\n",
    "            data = X[:BATCH_SIZE]\n",
    "            index = BATCH_SIZE\n",
    "        yield data\n",
    "\n",
    "\n",
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1], shape[2]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1], :] = img[:, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL = \"SNGAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-100000\n"
     ]
    }
   ],
   "source": [
    "if MODEL != \"VAE\":\n",
    "    MODEL == \"SNGAN\"\n",
    "    imported_meta = tf.train.import_meta_graph(\"./model/model.ckpt-100000.meta\")  \n",
    "    imported_meta.restore(session, tf.train.latest_checkpoint('./model/'))\n",
    "    image_input = session.graph.get_tensor_by_name(\"Placeholder_2:0\")\n",
    "    encoded = session.graph.get_tensor_by_name(\"critic_1/Reshape:0\")\n",
    "    critic_output = session.graph.get_tensor_by_name(\"Reshape_1:0\")\n",
    "else:\n",
    "    imported_meta = tf.train.import_meta_graph(\"./VAE_model/model.ckpt-125000.meta\")\n",
    "    imported_meta.restore(session, tf.train.latest_checkpoint('./VAE_model/'))\n",
    "    image_input = session.graph.get_tensor_by_name(\"Placeholder_1:0\")\n",
    "    encoded = session.graph.get_tensor_by_name(\"Encoder/flatten_1/Reshape:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    return np.log(1.0 + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoded_representation(X):\n",
    "    codes = []\n",
    "    batches = len(X) // 64\n",
    "    for i in range(batches):\n",
    "        images = X[i*64:(i+1)*64]\n",
    "        fd = {image_input: (images-127.5)/127.5}\n",
    "        code = session.run(encoded, feed_dict=fd)\n",
    "        codes.append(code)\n",
    "    codes = np.concatenate(codes, axis = 0)\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_IMAGES_SOURCE_DIR(MODE):\n",
    "    if MODE == \"train\":\n",
    "        IMAGES_SOURCE_DIR = TRAIN_IMAGES_DIR\n",
    "    elif MODE == \"test\":\n",
    "        IMAGES_SOURCE_DIR = TEST_IMAGES_DIR\n",
    "    elif MODE == \"generated\":\n",
    "        IMAGES_SOURCE_DIR = GENERATED_IMAGES_DIR\n",
    "    return IMAGES_SOURCE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"stats\")\n",
    "IMAGES_DIR = os.path.join(BASE_DIR, \"TSNE_images\")\n",
    "PLOTS_DIR = os.path.join(BASE_DIR, \"desktop_plots\")\n",
    "assert(os.path.exists(STATS_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_DIR = os.path.join(IMAGES_DIR, \"train\")\n",
    "TEST_IMAGES_DIR = os.path.join(IMAGES_DIR, \"test\")\n",
    "GENERATED_IMAGES_DIR = os.path.join(IMAGES_DIR, \"generated\")\n",
    "if not os.path.exists(IMAGES_DIR):\n",
    "    os.mkdir(IMAGES_DIR)\n",
    "    os.mkdir(TRAIN_IMAGES_DIR)\n",
    "    os.mkdir(TEST_IMAGES_DIR)\n",
    "    os.mkdir(GENERATED_IMAGES_DIR)\n",
    "else:\n",
    "    if not os.path.exists(TRAIN_IMAGES_DIR):\n",
    "        os.mkdir(TRAIN_IMAGES_DIR)\n",
    "    if not os.path.exists(TEST_IMAGES_DIR):\n",
    "        os.mkdir(TEST_IMAGES_DIR)\n",
    "    if not os.path.exists(GENERATED_IMAGES_DIR):\n",
    "        os.mkdir(GENERATED_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource, reset_output, output_notebook\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.models import CategoricalColorMapper\n",
    "reset_output()\n",
    "\n",
    "TOOLTIPS = \"\"\"\n",
    "    <div>\n",
    "        <div>\n",
    "            <img\n",
    "                src=\"@imgs\" height=\"64\" width=\"64\"\n",
    "                style=\"float: left; margin: 0px 15px 15px 0px;\"\n",
    "                border=\"2\"\n",
    "            ></img>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "def plot(MODE, projection):\n",
    "    IMAGES_SOURCE_DIR = get_IMAGES_SOURCE_DIR(MODE)\n",
    "    if MODE != \"generated\":\n",
    "        source = ColumnDataSource(data=dict(\n",
    "            x=projection[:,0],\n",
    "            y=projection[:,1],\n",
    "            imgs=[os.path.join(IMAGES_SOURCE_DIR, str(i)+\".png\") for i in range(MAX_PROJECTIONS)],\n",
    "            labels = [CATEGORY_DICT[i] for i in y]\n",
    "        ))\n",
    "        color_map = CategoricalColorMapper(factors=list(CATEGORY_DICT.values()),\n",
    "                                       palette=d3['Category10'][10])\n",
    "        color = {'field': 'labels', 'transform': color_map}\n",
    "        legend = 'labels'\n",
    "        p = figure(plot_width=1600, plot_height=800, tooltips=TOOLTIPS,\n",
    "               title=MODE)\n",
    "        p.circle('x', 'y', color=color, size=10, source=source, legend=legend)\n",
    "    else:\n",
    "        source = ColumnDataSource(data=dict(\n",
    "            x=projection[:,0],\n",
    "            y=projection[:,1],\n",
    "            imgs=[os.path.join(IMAGES_SOURCE_DIR, str(i)+\".png\") for i in range(MAX_PROJECTIONS)]))\n",
    "        color_map = None\n",
    "        color = None\n",
    "        legend = None\n",
    "        p = figure(plot_width=1600, plot_height=800, tooltips=TOOLTIPS,\n",
    "               title=MODE)\n",
    "        p.circle('x', 'y', size=10, source=source)\n",
    "\n",
    "    output_file(os.path.join(PLOTS_DIR, MODEL+\"_\"+MODE+\"_tsne.html\"))\n",
    "\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDICT = {\"train\":{}, \"test\":{}, \"generated\":{}}\\nMAX_PROJECTIONS = 64 * (600 // 64)\\nfor MODE in [\"generated\", \"test\", \"train\"]:\\n    fname = os.path.join(STATS_DIR, MODE+\"_outputs.pkl\")\\n    with open(fname, \"rb\") as f:\\n        d = pickle.load(f)\\n    X = d[\"images\"]\\n    y = np.array(d[\"labels\"]) if d[\"labels\"] is not None else None\\n    d_out = np.array(d[\"critic_outputs\"])\\n\\n    IMAGES_SOURCE_DIR = get_IMAGES_SOURCE_DIR(MODE)\\n\\n    perm = np.random.permutation(len(X))\\n    DICT[MODE][\"X\"] = X[perm][:MAX_PROJECTIONS]\\n    DICT[MODE][\"y\"] = y[perm][:MAX_PROJECTIONS] if y is not None else None\\n    DICT[MODE][\"d_out\"] = d_out[perm][:MAX_PROJECTIONS]\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "DICT = {\"train\":{}, \"test\":{}, \"generated\":{}}\n",
    "MAX_PROJECTIONS = 64 * (600 // 64)\n",
    "for MODE in [\"generated\", \"test\", \"train\"]:\n",
    "    fname = os.path.join(STATS_DIR, MODE+\"_outputs.pkl\")\n",
    "    with open(fname, \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    X = d[\"images\"]\n",
    "    y = np.array(d[\"labels\"]) if d[\"labels\"] is not None else None\n",
    "    d_out = np.array(d[\"critic_outputs\"])\n",
    "\n",
    "    IMAGES_SOURCE_DIR = get_IMAGES_SOURCE_DIR(MODE)\n",
    "\n",
    "    perm = np.random.permutation(len(X))\n",
    "    DICT[MODE][\"X\"] = X[perm][:MAX_PROJECTIONS]\n",
    "    DICT[MODE][\"y\"] = y[perm][:MAX_PROJECTIONS] if y is not None else None\n",
    "    DICT[MODE][\"d_out\"] = d_out[perm][:MAX_PROJECTIONS]\n",
    "    for i in range(len(DICT[MODE][\"X\"])):\n",
    "        imsave(os.path.join(IMAGES_SOURCE_DIR, str(i)+\".png\"), DICT[MODE][\"X\"][i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(STATS_DIR, \"TSNE.pkl\")\n",
    "with open(fname, \"rb\") as f:\n",
    "    DICT = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudeep/.conda/envs/keras_gpu_tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:11: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/home/sudeep/.conda/envs/keras_gpu_tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:11: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/home/sudeep/.conda/envs/keras_gpu_tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:11: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "CODES = []\n",
    "MAX_PROJECTIONS = 64 * (600 // 64)\n",
    "for MODE in [\"generated\", \"test\", \"train\"]:\n",
    "\n",
    "    X = DICT[MODE]['X']\n",
    "    y = DICT[MODE]['y'] \n",
    "    d_out = DICT[MODE]['d_out']\n",
    "    IMAGES_SOURCE_DIR = get_IMAGES_SOURCE_DIR(MODE)\n",
    "    \n",
    "    codes = get_encoded_representation(X)\n",
    "    CODES.append(codes)\n",
    "    tsne = TSNE()\n",
    "    projections = tsne.fit_transform(codes)\n",
    "    plot(MODE, projections)\n",
    "CODES = np.concatenate(CODES, axis = 0)\n",
    "tsne = TSNE()\n",
    "PROJECTIONS = tsne.fit_transform(CODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECTIONS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 8192)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CODES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25192285, -0.0013653218)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.max(CODES, axis=0)), np.mean(np.min(CODES, axis= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = ColumnDataSource(data=dict(\n",
    "    x=PROJECTIONS[:,0],\n",
    "    y=PROJECTIONS[:,1],\n",
    "    imgs=[os.path.join(GENERATED_IMAGES_DIR, str(i)+\".png\") for i in range(MAX_PROJECTIONS)]\\\n",
    "    +[os.path.join(TEST_IMAGES_DIR, str(i)+\".png\") for i in range(MAX_PROJECTIONS)]\\\n",
    "    +[os.path.join(TRAIN_IMAGES_DIR, str(i)+\".png\") for i in range(MAX_PROJECTIONS)],\n",
    "    labels = [\"generated\"]*(len(PROJECTIONS)//3) +  [\"test\"]*(len(PROJECTIONS)//3) \\\n",
    "    + [\"train\"]*(len(PROJECTIONS)//3)\n",
    "    ))\n",
    "color_map = CategoricalColorMapper(factors=[\"generated\", \"test\", \"train\"], palette=d3['Category10'][3])\n",
    "color = {'field': 'labels', 'transform': color_map}\n",
    "legend = 'labels'\n",
    "p = figure(plot_width=1600, plot_height=800, tooltips=TOOLTIPS, title=\"Combined projections\")\n",
    "p.circle('x', 'y', color=color, size=10, source=source, legend=legend)\n",
    "output_file(os.path.join(PLOTS_DIR, MODEL+\"_Combined_tsne.html\"))\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras_gpu_tensorflow]",
   "language": "python",
   "name": "conda-env-keras_gpu_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
